<h1 align="center"> Introduction to Artificial Intelligence and Machine Learning</h1>
<br>
<p align='center'><img widht="900" src="https://cdn.business2community.com/wp-content/uploads/2018/01/what-is-machine-learning-dilbert.png"></p>
<br>
<br>
<h2> The Background Story and History of ML/AI:</h2>
<br>
<br>

### From Theory to Reality:

* **Pre 1940s:** Many of the major mathematical concepts of modern machine learning came from statistics. Few of those major breakthroughs
include **Bayes Thearem(1812)**, **Least Square Method(1805)**, **Markov Chain(1913)**. These techniques are all fundamental to
modern machine learning.
<br>
<br>



* **AI Debuts on the silver Screen(1927):** The sci-fi film **Metropolis** set in 2026 Berlin, introduced the audiences the idea
thinking machine. The character **False Maria** was the first robot ever depicted in a film.
<br>
<br>

<p align='center'><a href="https://www.youtube.com/watch?v=on2H8Qt5fgA" target="_blank">
<img style="border: 2px solid red" src="https://i1.wp.com/illuminatiwatcher.com/wp-content/uploads/2015/04/WO-Metropolis-False-Maria-Robot-Pentagram.jpg?w=450&ssl=1" 
alt="FALSE MARIA" width="600" height="400" border="10" /></a></p>

[YouTube Link](https://www.youtube.com/watch?v=on2H8Qt5fgA)

<br>
<br>


* **The Turing Test(1950):** Alan Turing an English Mathematician considered as the father of artificial intelligence,
created the **Turing Test** to determine if a computer has a real intelligence. To pass the test, a computer must be able to fool a human into believing
if it is also human.

<p align='center'><img width="200" src="https://upload.wikimedia.org/wikipedia/commons/a/a1/Alan_Turing_Aged_16.jpg"></p>

###### Turing Test
<p align='center'><img src="https://miro.medium.com/max/678/0*dGRyc5T7yqU6MRJH."></p>
<br>
<p align='center'><img width="500" src="https://i.pinimg.com/736x/47/14/eb/4714eb4d37d451c394b904197e40c4db.jpg"></p>
<!---
According to this kind of test, a computer is deemed to have artificial intelligence if it can mimic human responses under specific conditions.
In the basic Turing Test, there are three points. Two of the points are operated by humans, and the third point is operated by a computer. 
Each point is physically separated from the other two. One human is designated as the questioner. 
The other human and the computer are designated the respondents. The questioner interrogates both the human respondent and the computer according to a specified format, 
within a certain subject area and context, and for a preset length of time (such as 10 minutes). 
After the specified time, the questioner tries to decide which point is operated by the human respondent, 
and which one is operated by the computer. The test is repeated many times. 
If the questioner makes the correct determination in half of the test runs or less, the computer is considered to have artificial intelligence, 
because the questioner regards it as “just as human” as the human respondent.
-->

<br>
<br>

* **First Computer Learning Program(1952):** Machine learning pioneer Arthur Samuel created a program that helped an IBM computer get better at checkers the more it played.
Machine learning scientists often use board games because they are both understandable and complex.
<p align='center'><img width="500" src="https://lh3.googleusercontent.com/LwWR7kFeDM_sZmGKgehZXRZXGJz6iwxazEHpGxWWTlKmXfWwq78wobI6vTPiRo5DG1o=s1200"></p>
<br>
<br>

* **The Perceptron(1957):** Frank Rosenblatt – at the Cornell Aeronautical Laboratory – combined Donald Hebb’s model of brain cell interaction with Arthur Samuel’s Machine Learning efforts and created the perceptron. 
The perceptron was initially planned as a machine, not a program. 
The software, originally designed for the IBM 704, was installed in a custom-built machine called the Mark 1 perceptron, which had been constructed for image recognition.

<p align='center'><img width="400" src="https://miro.medium.com/max/392/0*GyDjJC-LfR2TNX6n."></p>

>Although the perceptron seemed promising, it could not recognize many kinds of visual patterns (such as faces), 
causing frustration and stalling neural network research. It would be several years before the frustrations of investors and funding agencies faded. 
Neural network/Machine Learning research struggled until a resurgence during the 1990s.
<p align='center'><img width="400" src="https://missinglink.ai/wp-content/uploads/2018/11/multilayer-perceptron.png"></p>

<!---
Machine Learning is, in part, based on a model of brain cell interaction. 
The model was created in 1949 by Donald Hebb in a book titled The Organization of Behavior (PDF). 
The book presents Hebb’s theories on neuron excitement and communication between neurons.
-->

<br>
<br>

* **The Nearest Neignbor Algorithm(1967):** The **Nearest Neighbor** algorithm was written, allowing computers to begin using very basic pattern recognition.
When the program was given a new object, it compared it with the existing data and classified it to the nearest neighbour, meaning the most similar object in memory.
This algorithm was used for mapping routes and was one of the earliest algorithms used in finding a solution to the **Traveling Salesperson’s** problem of finding the most efficient route.
Using it, a salesperson enters a selected city and repeatedly has the program visit the nearest cities until all have been visited.

<br>

<h4 align="center"> The Thinking Machine(Artificial Intelligence in the 1960s)</h4>
<p align='center'><a href="https://www.youtube.com/watch?time_continue=167&v=aygSMgK3BEM" target="_blank">
<img src="https://i.ibb.co/4VMHGsK/thinking-machine.png" width="400">
</a></p>

[YouTube Link](https://www.youtube.com/watch?time_continue=167&v=aygSMgK3BEM)

<br>
<br>

* **The years of 1970s and early 1980s:** In the late 1970s and early 1980s, neural network research was abandoned by computer science and AI researchers. 
The Machine Learning industry, which included a large number of researchers and technicians, was reorganized into a separate field and struggled for nearly a decade.
The industry goal shifted from training for Artificial Intelligence to solving practical problems in terms of providing services.
Its focus shifted from the approaches inherited from AI research to methods and tactics used in probability theory and statistics.
During this time, the ML industry maintained its focus on neural networks and then flourished in the 1990s.
Most of this success was a result of Internet growth, benefiting from the ever-growing availability of digital data and the ability to share its services by way of the Internet.

<br>
<br>

* **Back Propagation(1986):** Though **Back Propagation** was dreived by multiple researchers in the early 60s. However it was untill 1986,
with the publishing of a paper by Rumelhart, **Hinton**, and Williams, titled "Learning Representations by Back-Propagating Errors," that
the importance of the algorithm was appreciated by the machine learning community at large.  Yann LeCun, inventor of the Convolutional Neural Network architecture, 
proposed the modern form of the back-propagation learning algorithm for neural networks in his PhD thesis in 1987. But it is only much later, in 1993, 
that Wan was able to win an international pattern recognition contest through backpropagation
> By the 1980s, hand-engineering features had become the de facto standard in many fields, especially in computer vision,
since experts knew from experiments which features (e.g. lines, circles, edges, blobs in computer vision) made learning simpler.
However, hand-engineering successful features requires a lot of knowledge and practice. More importantly, since it is not automatic, it is usually very slow.
> Backpropagation was one of the first methods able to demonstrate that artificial neural networks could learn good internal representations, 
i.e. their hidden layers learned nontrivial features. Even more importantly, because of the efficiency of the algorithm and the fact that domain experts were no longer required to discover appropriate features, 
backpropagation allowed artificial neural networks to be applied to a much wider field of problems that were previously off-limits due to time and cost constraints.
<br>

<p align='center'><img src="https://pbs.twimg.com/media/D1odAE7XgAAHhYx.png"></p>


<br>
<br>

* **Machine Learning Applications(1990s):** Work on machine learning shifts from a knowledge-driven approach to a data-driven approach.  Scientists begin creating programs for computers to analyze large amounts of data and draw conclusions — or “learn” — from the results. we began to apply machine learning in data mining, adaptive software and web applications, text learning, and language learning. Scientists begin creating programs for computers to analyze large amounts of data and draw conclusions — or “learn” — from the results.

<br>
<br>

* **Deep Blue Beats Garry Kasparov(1996):** Public awareness of AI increased greatly when an IBM computer named Deep Blue beat world chess champion Garry Kasparov in the first game of a match.
Kasparov won the 1996 match, but in 1997 an upgraded Deep Blue then won a second match 3½ games to 2½. Although Deep Blue played an impressive game of chess it largely relied on brute computing power to achieve this, including 480 special purpose ‘chess chips’. It worked by searching from 6-20 moves ahead at each position, having learned by evaluating thousands of old chess games to determine the path to checkmate.

<p align='center'><img src="https://ichef.bbci.co.uk/images/ic/496xn/p0549xh4.jpg"></p>

[YouTube Link](https://www.youtube.com/watch?v=KF6sLCeBj0s)

<br>
<br><h1 align="center"> Introduction to Artificial Intelligence and Machine Learning</h1>
<br>
<p align='center'><img widht="900" src="https://cdn.business2community.com/wp-content/uploads/2018/01/what-is-machine-learning-dilbert.png"></p>
<br>
<br>
<h2> The Background Story and History of ML/AI:</h2>
<br>
<br>

### From Theory to Reality:

* **Pre 1940s:** Many of the major mathematical concepts of modern machine learning came from statistics. Few of those major breakthroughs
include **Bayes Theorem(1812)**, **Least Square Method(1805)**, **Markov Chain(1913)**. These techniques are all fundamental to
modern machine learning.
<br>
<br>



* **AI Debuts on the Silver Screen(1927):** The sci-fi film **Metropolis** set in 2026 Berlin, introduced the audiences the idea
thinking machine. The character **False Maria** was the first robot ever depicted in a film.
<br>
<br>

<p align='center'><a href="https://www.youtube.com/watch?v=on2H8Qt5fgA" target="_blank">
<img style="border: 2px solid red" src="https://i1.wp.com/illuminatiwatcher.com/wp-content/uploads/2015/04/WO-Metropolis-False-Maria-Robot-Pentagram.jpg?w=450&ssl=1"
alt="FALSE MARIA" width="600" height="400" border="10" /></a></p>

[YouTube Link](https://www.youtube.com/watch?v=on2H8Qt5fgA)

<br>
<br>


* **The Turing Test(1950):** Alan Turing an English Mathematician considered as the father of artificial intelligence,
created the **Turing Test** to determine if a computer has real intelligence. To pass the test, a computer must be able to fool a human into believing
if it is also human.

<p align='center'><img width="200" src="https://upload.wikimedia.org/wikipedia/commons/a/a1/Alan_Turing_Aged_16.jpg"></p>

###### Turing Test
<p align='center'><img src="https://miro.medium.com/max/678/0*dGRyc5T7yqU6MRJH."></p>
<br>
<p align='center'><img width="500" src="https://i.pinimg.com/736x/47/14/eb/4714eb4d37d451c394b904197e40c4db.jpg"></p>
<!---
According to this kind of test, a computer is deemed to have artificial intelligence if it can mimic human responses under specific conditions.
In the basic Turing Test, there are three points. Two of the points are operated by humans, and the third point is operated by a computer.
Each point is physically separated from the other two. One human is designated as the questioner.
The other human and the computer are designated the respondents. The questioner interrogates both the human respondent and the computer according to a specified format,
within a certain subject area and context, and for a preset length of time (such as 10 minutes).
After the specified time, the questioner tries to decide which point is operated by the human respondent,
and which one is operated by the computer. The test is repeated many times.
If the questioner makes the correct determination in half of the test runs or less, the computer is considered to have artificial intelligence,
because the questioner regards it as “just as human” as the human respondent.
-->

<br>
<br>

* **First Computer Learning Program(1952):** Machine learning pioneer Arthur Samuel created a program that helped an IBM computer get better at checkers the more it played.
Machine learning scientists often use board games because they are both understandable and complex.
<p align='center'><img width="500" src="https://lh3.googleusercontent.com/LwWR7kFeDM_sZmGKgehZXRZXGJz6iwxazEHpGxWWTlKmXfWwq78wobI6vTPiRo5DG1o=s1200"></p>
<br>
<br>

* **The Perceptron(1957):** Frank Rosenblatt – at the Cornell Aeronautical Laboratory – combined Donald Hebb’s model of brain cell interaction with Arthur Samuel’s Machine Learning efforts and created the perceptron.
The perceptron was initially planned as a machine, not a program.
The software, originally designed for the IBM 704, was installed in a custom-built machine called the Mark 1 perceptron, which had been constructed for image recognition.

<p align='center'><img width="400" src="https://miro.medium.com/max/392/0*GyDjJC-LfR2TNX6n."></p>

>Although the perceptron seemed promising, it could not recognize many kinds of visual patterns (such as faces),
causing frustration and stalling neural network research. It would be several years before the frustrations of investors and funding agencies faded.
Neural network/Machine Learning research struggled until a resurgence during the 1990s.
<p align='center'><img width="400" src="https://missinglink.ai/wp-content/uploads/2018/11/multilayer-perceptron.png"></p>

<!---
Machine Learning is, in part, based on a model of brain cell interaction.
The model was created in 1949 by Donald Hebb in a book titled The Organization of Behavior (PDF).
The book presents Hebb’s theories on neuron excitement and communication between neurons.
-->

<br>
<br>

<!--
* **The Nearest Neighbor Algorithm(1967):** The **Nearest Neighbor** algorithm was written, allowing computers to begin using very basic pattern recognition.
When the program was given a new object, it compared it with the existing data and classified it to the nearest neighbor, meaning the most similar object in memory.
This algorithm was used for mapping routes and was one of the earliest algorithms used in finding a solution to the **Traveling Salesperson’s** problem of finding the most efficient route.
Using it, a salesperson enters a selected city and repeatedly has the program visit the nearest cities until all have been visited.
<br>
<h4 align="center"> The Thinking Machine(Artificial Intelligence in the 1960s)</h4>
<p align='center'><a href="https://www.youtube.com/watch?time_continue=167&v=aygSMgK3BEM" target="_blank">
<img src="https://i.ibb.co/4VMHGsK/thinking-machine.png" width="400">
</a></p>
[YouTube Link](https://www.youtube.com/watch?time_continue=167&v=aygSMgK3BEM)
<br>
<br>
-->

* **The years of the 1970s and early 1980s:** In the late 1970s and early 1980s, neural network research was abandoned by computer science and AI researchers.
The Machine Learning industry, which included a large number of researchers and technicians, was reorganized into a separate field and struggled for nearly a decade.
The industry goal shifted from training for Artificial Intelligence to solving practical problems in terms of providing services.
Its focus shifted from the approaches inherited from AI research to methods and tactics used in probability theory and statistics.
During this time, the ML industry maintained its focus on neural networks and then flourished in the 1990s.
Most of this success was a result of Internet growth, benefiting from the ever-growing availability of digital data and the ability to share its services by way of the Internet.

<br>
<br>

* **Back Propagation(1986):** Though **Back Propagation** was derived by multiple researchers in the early 60s. However it was until 1986,
with the publishing of a paper by Rumelhart, **Hinton**, and Williams, titled "Learning Representations by Back-Propagating Errors," that
the importance of the algorithm was appreciated by the machine learning community at large.  Yann LeCun, the inventor of the Convolutional Neural Network architecture,
proposed the modern form of the back-propagation learning algorithm for neural networks in his Ph.D. thesis in 1987. But it is only much later, in 1993,
that Wan was able to win an international pattern recognition contest through backpropagation
> By the 1980s, hand-engineering features had become the de facto standard in many fields, especially in computer vision,
since experts knew from experiments which feature (e.g. lines, circles, edges, blobs in computer vision) made learning simpler.
However, hand-engineering successful features require a lot of knowledge and practice. More importantly, since it is not automatic, it is usually very slow.
> Backpropagation was one of the first methods able to demonstrate that artificial neural networks could learn good internal representations,
i.e. their hidden layers learned nontrivial features. Even more importantly, because of the efficiency of the algorithm and the fact that domain experts were no longer required to discover appropriate features,
backpropagation allowed artificial neural networks to be applied to a much wider field of problems that were previously off-limits due to time and cost constraints.
<br>

<p align='center'><img src="https://pbs.twimg.com/media/D1odAE7XgAAHhYx.png"></p>


<br>
<br>

* **Machine Learning Applications (the 1990s):** Work on machine learning shifts from a knowledge-driven approach to a data-driven approach.  Scientists begin creating programs for computers to analyze large amounts of data and draw conclusions — or “learn” — from the results. we began to apply machine learning in data mining, adaptive software and web applications, text learning, and language learning. Scientists begin creating programs for computers to analyze large amounts of data and draw conclusions — or “learn” — from the results.

<br>
<br>

* **Deep Blue Beats Garry Kasparov(1996):** Public awareness of AI increased greatly when an IBM computer named Deep Blue beat world chess champion Garry Kasparov in the first game of a match.
Kasparov won the 1996 match, but in 1997 an upgraded Deep Blue then won a second match 3½ games to 2½. Although Deep Blue played an impressive game of chess it largely relied on brute computing power to achieve this, including 480 special purposes ‘chess chips’. It worked by searching from 6-20 moves ahead at each position, having learned by evaluating thousands of old chess games to determine the path to checkmate.

<p align='center'><img src="https://ichef.bbci.co.uk/images/ic/496xn/p0549xh4.jpg"></p>

[YouTube Link](https://www.youtube.com/watch?v=KF6sLCeBj0s)

<br>
<br>

### Modern Machine Learning:

* **Neural Net research gets a reboot as "Deep Learning"(2006)**: Back in the early '80s when Hinton and his colleagues first started work on this idea, computers weren’t fast or powerful enough to process the enormous collections of data that neural nets require. Their success was limited, and the AI community turned its back on them, working to find shortcuts to brain-like behavior rather than trying to mimic the operation of the brain.

>But a few resolute researchers carried on. According to Hinton and LeCun, it was rough going. Even as late as 2004 – more than 20 years after Hinton and LeCun first developed the "back-propagation" algorithms that seeded their work on neural networks – the rest of the academic world was largely uninterested.

>But that year, with a small amount of funding from the Canadian Institute for Advanced Research (CIFAR) and the backing of LeCun and Bengio, Hinton founded the Neural Computation and Adaptive Perception program, an invite-only group of computer scientists, biologists, electrical engineers, neuroscientists, physicists, and psychologists.

<!--
Hand-picking these researchers, Hinton aimed to create a team of world-class thinkers dedicated to creating computing systems that mimic organic intelligence – or at least what we know about organic intelligence, what we know about how the brain sifts through a wealth of visual, auditory, and written cues to understand and respond to its environment. Hinton believed creating such a group would spur innovation in AI and maybe even change the way the rest of the world treated this kind of work.
-->

>By then, they had the computing power they needed to realize many of their earlier ideas. As they came together for regular workshops, their research accelerated. They built more powerful deep learning algorithms that operated on much larger datasets. By the middle of the decade, they were winning global AI competitions. And by the beginning the current decade, the giants of the web began to notice.

<!--
<p align='center'><img src="https://images.thestar.com/wgf2KXhd5xhhKyMIEk-VAXShecA=/1200x799/smart/filters:cb(2700061000)/https://www.thestar.com/content/dam/thestar/news/world/2015/04/17/how-a-toronto-professors-research-revolutionized-artificial-intelligence/geoffrey-hinton-3.jpg" width="500"></p>
-->

[YouTube Link](https://youtu.be/uAu3jQWaN6E)
[For more info](https://www.wired.com/2014/01/geoffrey-hinton-deep-learning/)

<br>
<br>

<!--
* **CNN, LeNet5 and AlexNet and use of GPU in Machine Learning(2012):** It is the year 1994, and this is one of the very first convolutional neural networks, and what propelled the field of Deep Learning. This pioneering work by Yann LeCun was named LeNet5 after many previous successful iterations since the year 1988.
<p align='center'><img src="https://cdn-images-1.medium.com/max/800/0*V1vb9SDnsU1eZQUy.jpg"></p>
In the years from 1998 to 2010 neural networks were in incubation. Most people did not notice their increasing power, while many other researchers slowly progressed. More and more data was available because of the rise of cell-phone cameras and cheap digital cameras. And computing power was on the rise, CPUs were becoming faster, and GPUs became a general-purpose computing tool. Both of these trends made neural network progress, albeit at a slow rate. Both data and computing power made the tasks that neural networks tackled more and more interesting. And then it became clear…
-->

* **The AlexNet and use of GPU in Machine Learning (2012):** In 2012, Alex Krizhevsky released AlexNet which was a deeper and much wider version of the LeNet and won by a large margin the difficult ImageNet competition.
AlexNet is considered one of the most influential papers published in computer vision, has spurred many more papers published employing CNNs and GPUs to accelerate deep learning.

<!--
AlexNet was not the first fast GPU-implementation of a CNN to win an image recognition contest. A CNN on GPU by K. Chellapilla et al. (2006) was 4 times faster than an equivalent implementation on CPU. A deep CNN of Dan Ciresan et al. (2011) at IDSIA was already 60 times faster and achieved superhuman performance in August 2011. Between May 15, 2011, and September 10, 2012, CNN won no fewer than four image competitions. They also significantly improved on the best performance in the literature for multiple image databases.
According to the AlexNet paper, Ciresan's earlier net is "somewhat similar." Both were originally written with CUDA to run with GPU support. In fact, both are actually just variants of the CNN designs introduced by Yann LeCun et al. (1989) who applied the backpropagation algorithm to a variant of Kunihiko Fukushima's original CNN architecture called "recognition." The architecture was later modified by J. Weng's method called max-pooling
-->

<p align='center'><img src="https://cms.qz.com/wp-content/uploads/2018/06/2018-05-11-Alex-Krizhevsky-8394-e1529095310611.jpg?quality=75&strip=all&w=410&h=231"></p>

[Alex Krizhevsky](https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley/)

### Advances in Machine Learning from then on

* **GoogleBrain (2012)**: This was a deep neural network created by Jeff Dean of Google, which focused on pattern detection in images and videos. It was able to use Google’s resources, which made it incomparable to much smaller neural networks. It was later used to detect objects in YouTube videos. [YouTube Link](https://www.youtube.com/watch?v=B15gWiOI64s)

<br>
<br>

* **DeepFace (2014):** This is a Deep Neural Network created by Facebook, which they claimed can recognize people with the same precision as a human can.

<br>
<br>

* **DeepMind (2014):** This company was bought by Google, and can play basic video games to the same levels as humans. In 2016, it managed to beat a professional at the game Go, which is considered to be one of the world’s most difficult board games.
[YouTube Link](https://www.youtube.com/watch?v=8dMFJpEGNLQ)

<br>
<br>

* **OpenAI (2015):** This is a non-profit organization created by Elon Musk and others, to create safe artificial intelligence that can benefit humanity. OpenAI Five is the first AI to beat the world champions in
an esports game after defeating the reigning Dota 2 world champions, OG, at the OpenAI Five Finals on April 13, 2019.
OpenAI Five plays 180 years' worth of games against itself every day, learning via self-play.

<p align='center'><img width="500" src="https://openai.com/content/images/2018/06/group-laptop.jpg"></p>

[YouTube Link](https://youtu.be/UZHTNBMAfAA)

<br>
<br>

* **Amazon Machine Learning Platform (2015):** This is part of Amazon Web Services and shows how most big companies want to get involved in machine learning. They say it drives many of their internal systems, from regularly used services such as search recommendations and Alexa to more experimental ones like Prime Air and Amazon Go.

<br>
<br>

* **YOLO - You Only Look Once: Unified, Real-Time Object Detection (2016):**
[Official Link](https://pjreddie.com/darknet/yolo/)

<br>
<br>

* **General Adversarial Network (2014):** Way back in 2014, Ian Goodfellow proposed a revolutionary idea — make two neural networks compete (or collaborate, it’s a matter of perspective) with each other.


One neural network tries to generate realistic data (note that GANs can be used to model any data distribution, but are mainly used for images these days), and the other network tries to discriminate between real data and data generated by the generator network.

Yann LeCun, Facebook’s chief AI scientist, has called GANs “the coolest idea in deep learning in the last 20 years.”

<p align='center'><img width="500" src="https://miro.medium.com/max/1316/1*HaExieykcOT5oI2_xKisrQ.png"></p>

<p align='center'><img width="500" src="https://miro.medium.com/max/1682/1*UsiBSjHy8ut5GSAT8f7bIQ.png"></p>

<br>
<br>

<!--
The Importance of GPUs
Nvidia is behind one of the largest conferences on AI, and this is for a good reason - GPUs are extremely important in the world of machine learning. GPUs have around 200 times more processors per chip than CPUs. The flip side of this, however, is that whereas CPUs can perform any kind of computation, GPUs are tailored to only specific use cases, where operations (addition, multiplication, etc.) have to be performed on vectors, which are essentially lists of numbers. A CPU would perform each operation on each number in the vector synchronously, i.e. one by one. This is slow. A GPU would perform operations on each number in the vector in parallel i.e. at the same time.
Vectors and matrices, which are grids of numbers (or lists of vectors) are essential to machine learning applications, and because of this, they are smaller, hence why more can be fit on one chip. Nvidia is credited with making the world’s first GPU, the GeForce 256 in 1999. At that time, launching the product was a risk as it was an entirely new kind of product. However, due to the use of vector calculations in video games, GPUs proliferated, as video games benefitted from a huge leap in performance. It was years later than mathematicians, scientists and engineers realized that GPUs could be used to improve the speed of computations used in their discipline, due to the use of vectors. This led to the realization that GPUs would make neural networks, a very old idea, leaps, and bounds more practical. This led to GPU companies particularly Nvidia benefitting hugely from the “machine learning revolution”. Nvidia’s stock price has increased roughly 18-fold since 2012, the year in which the importance of GPUs in machine learning was demonstrated by AlexNet.

-->

#### 2018 Turing Award Winners
<br>

<p align='center'><img width="700" src="https://awards.acm.org/binaries/content/gallery/acm/ctas/awards/turing-2018-bengio-hinton-lecun.jpg"></p>
<br>

#### Honourable Mention
<br>
<p align='center'><img width="500" src="https://miro.medium.com/max/3200/1*FGGge_GilZ_KJYaoryaxkA.png"></p>
<br>
<p align='center'><img width="400" src="https://miro.medium.com/max/1080/1*GPas2MBwIQDzkDkDxMNI9w.jpeg"></p>
<h4 align="center"> Andrew Ng</h1>
<br>
<br>
<br>
<br>
<br>
<br>

## Misconceptions about ML/AI:
<br>
<p align='center'><img width="400" src="https://images-cdn.9gag.com/photo/aOYA1mE_700b.jpg"></p>
<br>
<p align='center'><img width="500" src="https://external-preview.redd.it/B_lQeKFyKYYGhEiMc3-FmczG4HxqnDMBtiWYNVcaExg.jpg?auto=webp&s=163d0092dacc73edd486174d80f770bca2c72410"></p>
<br>

##### Using millions of if-else statements in your code means you’re already aware of those if-else conditions and you’re writing a program to tackle the situation.

##### AI on the other hand in simple words means a program taking care of the other scenarios too which it is NOT programmed for. That means the program learns with new conditions around the environment and evolves accordingly.

<br>

### Venn Diagram of ML/AI:

<br>

<p align="center"><img width="500" src="https://whatsthebigdata.files.wordpress.com/2016/10/ai_data-science-diagram.jpg?w=640"></p>

<br>

<p align="center"><img width="500" src="https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/20181109071100/machine-learning-AI-2.png"></p>

<br>
<br>
<br>
<br>

## Exciting things happening in the field of ML/AI:

<br>
<br>

<p align="center"><img width="700" src="https://www.3nions.com/wp-content/uploads/2019/07/2019-07-17_13-34-26.jpg"></p>
<h4 align="center">FaceApp</h4>
<br>

<p align="center"><img width="700" src="https://www.macblog.sk/wp/wp-content/uploads/2016/07/Prisma-iOS-Photo-Filter-App-Offers-Amazing-Effects-For-Free-.jpg"></p>
<h4 align="center">PRISMA</h4>
<br>
<br>
<br>

#### Okay time for something serious. Let's take a look at a few amazing scenarios where people are using ML/AI to solve real-world problems

* **AI can make realistic phone calls:** Last year during the Google I/O event google demonstrated their Duplex App, which successfully made a call with a hair salon and booked an appointment. The lady at the hair salon had no clue that she was talking to a computer.

<p align="center"><img width="500" src="https://i.ibb.co/DMqr5P7/duplex.png"></p>

[YouTube Link](https://www.youtube.com/watch?v=D5VN56jQMWM)

<br>
<br>

* **AI can find missing children:**  Nearly 3,000 missing children have been traced in four days, thanks to the facial recognition system (FRS) software that the Delhi Police is using on a trial basis to track down such children.

<p align="center"><img width="500" src="https://i.ndtvimg.com/i/2017-03/child-abuse-boy_650x400_51489589853.jpg"></p>

[Link to the article](https://www.ndtv.com/india-news/facial-recognition-system-helps-trace-3-000-missing-children-in-4-days-1841192)

<br>
<br>

* **AI can look through walls:** MIT recently announced that they had built an AI system that could literally ‘see’ people moving behind walls. They hooked up a neural network to a WIFI antenna and trained it to recognize the radio signals being bounced off people’s bodies. Over time, the network learned to recognize people and track their movements exactly, even in the dark or when they move behind walls.

[YouTube Link](https://youtu.be/HgDdaMy8KNE)

<br>
<br>

* **AI can diagnosis disease just by looking at your eyes:** To diagnose eye diseases, doctors often use an OCT scan. This is a scan where a beam of infrared light is bounced off the interior surfaces of the eye, to create a 3D scan of the eye tissues.
Google’s DeepMind division trained a neural network on a database of OCT scans and then let it compete with a panel of doctors. The AI managed to match the doctor’s diagnosis in 94% of all cases.
This is an astounding result. Six percent more and the AI would have been exactly as accurate as a panel of human doctors.

<p align="center"><img width="500" src="https://cdn.vox-cdn.com/thumbor/tlcEwBY3Qd_AOovEFLN2J85Q90E=/0x0:5616x3744/920x613/filters:focal(2359x1423:3257x2321):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/60819361/Close_up_of_an_OCT_machine_in_use_by_a_technician_performing_a_scan__1_.0.jpg"></p>

[Link to the article](https://www.theverge.com/2018/8/13/17670156/deepmind-ai-eye-disease-doctor-moorfields)

<br>
<br>

* **AI can turn Doodles into Stunning, Photorealistic Landscapes:** A deep learning model developed by NVIDIA Research can turn rough doodles into photorealistic masterpieces with breathtaking ease. The tool leverages generative adversarial networks, or GANs, to convert segmentation maps into lifelike images.

<p align="center"><img width="500" src="https://www.digitalartsonline.co.uk/cmsdata/features/3693907/nvidia-gaugan-opener.jpg"></p>

[YouTube Link](https://www.youtube.com/watch?v=p5U4NgVGAwg)

<br>
<br>

* **AI is helping in traffic control:** Together Artificial Intelligence (AI) and drones are becoming the smart eyes of smart cities with AI now helping to interpret and understand drone footage. Our work in the area is arming the Department of Transport's Road and Traffic Design team with essential data including vehicle type, speed and traffic flow at some of Melbourne’s busiest roundabouts. They are using the information to improve traffic modeling and understand the different behaviors of drivers at roundabouts.

[Video Link](https://www.instagram.com/p/B1GhIJIA8qO/?igshid=19912egvu9b8h)

<br>
<br>
<br>
<br>

# VERA


## What is the problem statement

Building a successful recommender system depends on understanding both the dimensions of people's preferences as well as their dynamics. Social trends are ever changing. Not only it is subjective to a person but it could have lot of features.

## What is vera trying to solve

Vera is in true sense a personalized recommendation system. You go to a shop, select an apparel and hang it in the vera setup. That's all.

Vera will show you recommendation based on that apparel. Not only that, It will also show what is currently trendy on the market based on that apparel. It will also show you styles that goes with this apparel.

## How are we tackling the problem

* **User walks in a store selects an apparel and hangs it on the vera setup** 
<br>
* **Crop top and bottom:** <br>  We crop out the parts of the image by running it through our object detection algorithm.
<br>
<br>
      <p align='center'><img src="https://i.imgur.com/ipJCG8k.jpg" width = "600"/></p>
    [How does object detection look like](https://streamable.com/wc8l4)
<br>


* **Colour of the apparel:** <br> We then find the segmentation map of the image. Segmentation map helps us find the colour of the cropped image
<br>
      <p align='center'>
          <img src="https://i.imgur.com/Yy8ReW6.png">
      </p>
    [How does segmentation look like](https://www.youtube.com/watch?v=akK5ui-vel0)
<br>
<br>

* **Find the top similar images from the inventory:**<br>
Now that we have the cropped images, we generate the embeddings of that  image. With the embeddings information along with the colour we feed it to our deep learning algorithm to give us back the top similar images as recommendation.
 Along with recommendation from inventory we also show the current social tends.
<br>
    <p align='center'>
          <img src="https://i.imgur.com/IUfW9Mr.jpg">
    </p>
    <p align='center'>
          <img src="https://i.imgur.com/gpW9q68.jpg">
    </p>
    <p align='center'>
          <img src="https://i.imgur.com/VN7nFIG.jpg">
    </p>
    <p align='center'>
          <img src="https://i.imgur.com/DTdkK53.jpg">
    </p>
* **Try the look ! :** <br> We are currently working towards showing **try the look**. We let user upload a photo and we supper impose that image with the apparel image using GAN networks.
<br>
<br>
      <p align='center'>
            <img src="https://i.imgur.com/iefatdL.png">
      </p>
      [paper link](https://arxiv.org/pdf/1906.01347.pdf)
                                                                                                                 
 # Course Structure 
We are going to discuss the theoretical concepts and the coding parts. 
You don't have to have a solid background on mathematics and python coding. Interested people can go through topics like linear algebra, probability, statistical concepts, python introduction etc.
      [great source](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists)          
These sessions are designed to get you up and running with the ml/deep learning concepts. Following are topics we will cover in detail.

* Introduction to Machine Learning
  
  * Linear Regression 
  * Logistic Regression
  * K-Means Clustering
  * Perceptron and Neural Networks

* Deep Learning
    * Backpropagation algorithm
    * Convolutional neural network
    * Simple classification on MNIST Dataset using CNN and then some real life classification problems
    * FACENet, for Face Recognition

Depending on the response we get from you guys we will add more advance topics like 
* How do you actually write a cnn from scratch
* How to train  segmentation , object detection models(models like [YOLO](https://pjreddie.com/darknet/yolo/), [Retinanet](https://github.com/fizyr/keras-retinanet), [Deeplab](https://github.com/tensorflow/models/tree/master/research/deeplab))
* Generative adversarial networks([GANS](https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/))






